{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart Disease Predictor.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmhYc5fIGXnuOsjnVYvIy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharineeshramtp2000/Iris-Flower-Type-Prediction-Logistic-Regression-/blob/master/Heart_Disease_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeaUi3cXjJ6",
        "colab_type": "text"
      },
      "source": [
        "Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gG7dpoXchH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1EEG2XqUH",
        "colab_type": "text"
      },
      "source": [
        "Importing the Dataset. Here we use the dataset from [ML Data](https://www.mldata.io/datasets/).\n",
        "![](https://www.gardendesign.com/pictures/images/900x705Max/site_3/iris-louisiana-black-gamecock-iris-beardless-louisiana-iris-shutterstock-com_12592.jpg)\n",
        "---\n",
        "The dataset consists of the following attriutes\n",
        "\n",
        "1.   Sepal Length (cm)\n",
        "2.   Sepal Width (cm)\n",
        "3.   Petal Length (cm)\n",
        "4.   Petal Width (cm)\n",
        "5.   Nominal: Iris Setosa, Iris Versicolour, Iris Virginica. This is the predictor class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifsPeCMYo2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dataset = pd.read_csv(\"iris_dataset.csv\")\n",
        "X = Dataset.iloc[:, :-1]\n",
        "y = Dataset.iloc[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbg5jOhBYx2V",
        "colab_type": "text"
      },
      "source": [
        "Now lets feature scale our independent variables from our famous [scikit](https://scikit-learn.org/stable/) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Widc4BbzZNvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CaoxRcZeMd",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset into training and testing and performing a good shuffle of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP83grDqZlOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, random_state = 42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82SIY2PZmNj",
        "colab_type": "text"
      },
      "source": [
        "Now lets define our Logistic Regression model.\n",
        "Here we define Stochastic Average Descen algorithm based LR.\n",
        "We can also use other methods like liblinear, LBFGS etc. as the dataset is small.\n",
        "\n",
        "Feel free to use the [Documnetaton for Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bLh52NbAxk",
        "colab_type": "code",
        "outputId": "3459237f-cb11-4953-cbb9-64f4a4e9e83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(max_iter=1000, random_state = 0, multi_class='ovr', solver='sag')\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='ovr', n_jobs=None, penalty='l2', random_state=0,\n",
              "                   solver='sag', tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j8E0L4b78d",
        "colab_type": "text"
      },
      "source": [
        "Now lets predict with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMBI0Utb_rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1xGFcQIcDJv",
        "colab_type": "text"
      },
      "source": [
        "Its time for evaluating our model.\n",
        "\n",
        "![](https://www.thinkebiz.net/wp-content/uploads/2018/01/74228032_s.jpg)\n",
        "\n",
        "---\n",
        "Lets first predict how our model is fitting for our training set\n",
        "We use the famous\n",
        "1.   f1 score\n",
        "2.   accuracy \n",
        "to evaluate the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjsrO7ycCIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AodntoNGc62e",
        "colab_type": "code",
        "outputId": "6b94eb91-87a8-4f58-ff3a-aa608d0ab6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_train = accuracy_score(y_train, classifier.predict(X_train))\n",
        "f1_train = f1_score(y_train, classifier.predict(X_train), average= 'weighted')\n",
        "\n",
        "print(\"Traing set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_train)\n",
        "print(\"F1 SCORE ---------------------->\",f1_train)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing set results\n",
            "ACCURACY ----------------------> 0.9222222222222223\n",
            "F1 SCORE ----------------------> 0.9221829900518426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGihP6W9d3-E",
        "colab_type": "text"
      },
      "source": [
        "Now lets see how well is our model. So now lets evaluate with our test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjgDCMbeCql",
        "colab_type": "code",
        "outputId": "d2bacb12-19ce-4ecf-f768-d5bce99065d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "f1_test = f1_score(y_test, y_pred, average= 'weighted')\n",
        "\n",
        "print(\"Test set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_test)\n",
        "print(\"F1 SCORE ---------------------->\",f1_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results\n",
            "ACCURACY ----------------------> 0.9166666666666666\n",
            "F1 SCORE ----------------------> 0.9163003663003664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2cFvHYehTh",
        "colab_type": "text"
      },
      "source": [
        "Now lets have our famous Confusion Matrix to visually understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MWd1w8etjW",
        "colab_type": "code",
        "outputId": "5b9f90b3-8e35-49d3-8c48-7cac94b086b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[23  0  0]\n",
            " [ 0 15  4]\n",
            " [ 0  1 17]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQxBHanoex-e",
        "colab_type": "text"
      },
      "source": [
        "Our model has worked well with our test set too.\n",
        "The **accuaracy** and **f1 score** for both test and training set is good.\n",
        "Its always to put a question and ask to ourselves that is this the best model?\n",
        "\n",
        "---\n",
        "\n",
        "Obvisouly not!\n",
        "We can still achive our accuracy by changing our models, changing the independent variables, change the metrics and so on.\n",
        "Its great that we have successfully implemented logistic regression with our fish species dataset."
      ]
    }
  ]
}